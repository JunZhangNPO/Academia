
- By Meta Facebook 
- Wav2vec works around this limitation by requiring little to no transcribed data. 
- The model uses self-supervision to push the boundaries by learning from unlabeled training data.
- The wav2vec model is trained by predicting speech units for masked parts of speech audio.
- It learns basic units that are 25ms long to enable learning of high-level contextualized representations. 
